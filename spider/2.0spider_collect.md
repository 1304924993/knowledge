
# 爬虫学习使用指南

>Auth: 王海飞
>
>Data：2018-06-15
>
>Email：779598160@qq.com
>
>github：https://github.com/coco369/knowledge 

### 前言

数据采集，针对网页获取源码，按照一定的正则匹配，或者xpath的规则去匹配出我们需要的结果，进行分类筛选入库等操作。在本章中会讲到requests，beautifulsoup等工具去爬取网页，获取相关需要的信息。


### 1. BeautifSoup

Beautiful Soup 是一个可以从HTML或XML文件中提取数据的Python库.它能够通过你喜欢的转换器实现惯用的文档导航,查找,修改文档的方式.Beautiful Soup会帮你节省数小时甚至数天的工作时间.-----引入[官网](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)的一句话

#### 1.1 安装

Beautiful Soup 4 通过PyPi发布,所以如果你无法使用系统包管理安装,那么也可以通过 easy_install 或 pip 来安装.包的名字是 beautifulsoup4 ,这个包兼容Python2和Python3.

	pip install beautifulsoup4

	pip install requests

#### 1.2 解析语法、find、find_all

##### find_all( name , attrs , recursive , text , **kwargs )

find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件


	1. 查询所有a标签的内容
	
		soup.find_all('a')
	
	2. 查询所有a标签下class样式为bb的内容
	
		soup.find_all('a', 'bb')
	
	3. 查询所有id样式为cc的内容

		soup.find_all(id='cc')
